<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>Tutorials & Demos - Justus Thies</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="Justus Thies" property="og:site_name">
  
    <meta content="Tutorials & Demos" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="Personal Website of Justus Thies covering his publications and teaching courses.
" property="og:description">
  
  
    <meta content="http://localhost:4000/tutorials/" property="og:url">
  
  
  
    <meta content="http://localhost:4000/assets/img/justus-thies.jpg" property="og:image">
  
  
  

    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@">
    <meta name="twitter:creator" content="@JustusThies">
  
    <meta name="twitter:title" content="Tutorials & Demos">
  
  
    <meta name="twitter:url" content="http://localhost:4000/tutorials/">
  
  
    <meta name="twitter:description" content="Personal Website of Justus Thies covering his publications and teaching courses.
">
  
  
    <meta name="twitter:image:src" content="http://localhost:4000/assets/img/justus-thies.jpg">
  

	<meta name="description" content="">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicon/apple-touch-icon-144x144.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="/"><img src="/assets/img/justus-thies.jpg" alt="Justus Thies"></a>
      </div>
      <div class="author-name">Justus Thies</div>
	  <div class="author-about">I am a postdoctoral researcher focusing on digital humans, video editing and forgery detection.</div>
    </div>
	

	<section class="subpages">	
		<a href="/publications"><div class="subpages-title">Publications</div></a>
    <a href="/teaching"><div class="subpages-title">Teaching</div></a>
    <a href="/tutorials"><div class="subpages-title">Tutorials  & Demos</div></a>
	</section>
	
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
          <li><a href="https://twitter.com/JustusThies" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://facebook.com/100012738961011" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
        
        
          <li class="github"><a href="http://github.com/justusthies" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
        
          <li class="email"><a href="mailto:justus.thies@tum.de"><i class="fa fa-envelope-o"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
        <p>2020 &copy; Justus Thies</p>

        <p>Website is based on <a href="https://github.com/artemsheludko/flexible-jekyll" target="_blank">flexible-jekyll</a>.</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->

<div class="content-box clearfix">
  <article class="article-page">
  <div class="page-content"> 
  
	<div class="wrap-content">
		<header class="header-page">
			<h1 class="page-title">Tutorials & Demos</h1>
		</header>
		<div class="page-description">Visual computing is a fast evolving field with a lot of real-world use cases. Especially, the synthesis of photo-realistic content and the modelling of digital humans raised a lot of attention. It is important for us to teach the broad public and to sensitize the people to possible image and video manipulations. We showed demonstrations of our methods at countless exhibitions and conferences, and also in TV reports and shows. Besides the demonstrations, we are also giving tutorials in our research field.
</div>
	</div>


	
	
		<hr>
		<h3 class="post-subtitle">2019</h3>
		<hr>
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face_berlin/thumb.jpg)" href="/posts/face_berlin/"></a>
	  
	  <div class="post-content">
		
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://niessnerlab.org/members/andreas_roessler/profile.html" target="_blank" rel="noopener noreferrer">Andreas Rössler</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face_berlin/">Cabinet Meeting&#58; Synthetic Media - Danger or Chance?</a></h2>


		<!--<p>In this session we showed several demonstrations of our current projects, to inform the Cabinet of Germany about the risks and the chances of synthetic...</p>-->
		<p>In this session we showed several demonstrations of our current projects, to inform the Cabinet of Germany about the risks and the chances of synthetic media.</p>
		<span class="post-date">2019, Nov 18&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			
		
			
			
		
		
			
		</div>
	</article>
	
	
		
			<br>
			<hr>
			<h3 class="post-subtitle">2018</h3>
			<hr>
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face_brussels/thumb.jpg)" href="/posts/face_brussels/"></a>
	  
	  <div class="post-content">
		
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face_brussels/">EU Commission&#58; Live Demo of Face2Face</a></h2>


		<!--<p>Invited by the EU Commission, we showed a live demo of Face2Face in Brussles. The topic of the conference was how to protect the election...</p>-->
		<p>Invited by the EU Commission, we showed a demo for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). The topic of the conference was how to protect the election process (EU elections 2019) against interference from outside (cyber crime, fake news).</p>
		<span class="post-date">2018, Oct 02&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://zollhoefer.com/papers/CACM19_F2F/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=eELKSAKBIIM" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/face_brussels/thies2016face.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face_tutorial/thumb.png)" href="/posts/face_tutorial/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face_tutorial/">ECCV 2018&#58; Tutorial on Face Tracking and its Applications</a></h2>


		<!--<p>Course Website The tutorial is about monocular face tracking techniques and also discusses the possible applications. Specifically, the tutorial will cover topics such as: Input...</p>-->
		<p>This invited tutorial is about monocular face tracking techniques and also discusses the possible applications. It is based on our Eurographics state-of-the-art report.</p>
		<span class="post-date">2018, Sep 08&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="http://zollhoefer.com/papers/EG18_FaceSTAR/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			
			
		
		
			<span class="post-paper-bibtex"><a href="/posts/face_tutorial/zollhoefer2018facestar.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/facestar_eg/teaser.jpg)" href="/posts/facestar_eg/"></a>
	  
	  <div class="post-content">
		
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://la.disneyresearch.com/people/derek-bradley/" target="_blank" rel="noopener noreferrer">Derek Bradley</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~pgarrido/index.html" target="_blank" rel="noopener noreferrer">Pablo Garrido</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://la.disneyresearch.com/people/thabo-beeler/" target="_blank" rel="noopener noreferrer">Thabo Beeler</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://ptrckprz.github.io/" target="_blank" rel="noopener noreferrer">Patrick Perez</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/facestar_eg/">Eurographics 2018&#58; State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications</a></h2>


		<!--<p>The computer graphics and vision communities have dedicated long standing efforts in building computerized tools for reconstructing, tracking, and analyzing human faces based on visual...</p>-->
		<p>This state-of-the-art report session summarizes recent trends in monocular facial performance capture and discusses its applications, which range from performance-based animation to real-time facial reenactment. We focus on methods where the central task is to recover and track a three dimensional model of the human face using optimization-based reconstruction algorithms.</p>
		<span class="post-date">2018, Apr 24&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="http://zollhoefer.com/papers/EG18_FaceSTAR/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			
			
		
		
			<span class="post-paper-bibtex"><a href="/posts/facestar_eg/zollhoefer2018facestar.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
			<br>
			<hr>
			<h3 class="post-subtitle">2017</h3>
			<hr>
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/facevr_et/thumb.jpg)" href="/posts/facevr_et/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/facevr_et/">SIGGRAPH Emerging Technologies&#58; Demo of FaceVR</a></h2>


		<!--<p>We propose FaceVR, a novel image-based method that enables video teleconferencing in VR based on self-reenactment. State-of-the-art face tracking methods in the VR context are...</p>-->
		<p>We present a novel method for the interactive markerless reconstruction of human heads using a single commodity RGB‐D sensor. Our entire reconstruction pipeline is implemented on the graphics processing unit and allows to obtain high‐quality reconstructions of the human head using an interactive and intuitive reconstruction paradigm.</p>
		<span class="post-date">2017, Aug 03&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://arxiv.org/abs/1610.03151" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=Lg-uGQLNJnQ" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/facevr_et/thies2017facevr_demo.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
			<br>
			<hr>
			<h3 class="post-subtitle">2016</h3>
			<hr>
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/faceincar/teaser.jpg)" href="/posts/faceincar/"></a>
	  
	  <div class="post-content">
		
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/faceincar/">FaceInCar Demo at the National IT Summit 2016</a></h2>


		<!--<p>This exhibit demonstrates the first approach for real-time dense face tracking of a driver based on a monocular video stream. It allows to reconstruct and...</p>-->
		<p>We demonstrate the capabilities of the dense face fitting proposed in Face2Face in the challenging scenario of face tracking in a car including occlusions and strong varying light situations.</p>
		<span class="post-date">2016, Nov 17&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">2 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			
		
			
			
		
		
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face2face_et/thumb.jpg)" href="/posts/face2face_et/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face2face_et/">SIGGRAPH Emerging Technologies&#58; Real-time Face Capture and Reenactment of RGB Videos</a></h2>


		<!--<p>We present a novel approach for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). The source sequence is also a monocular...</p>-->
		<p>We show a demo for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). Our goal is to animate the facial expressions of a target video by a source actor and re-render the manipulated output video in a photo-realistic fashion.</p>
		<span class="post-date">2016, Jul 28&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://dl.acm.org/citation.cfm?id=2929475" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=lBSFKSpwMQo" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/face2face_et/thies2016face2face_demo.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face2face_tv/thumb.jpg)" href="/posts/face2face_tv/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face2face_tv/">Live-demo of Face2Face in the Jimmy Kimmel Show</a></h2>


		<!--<p>





</p>-->
		<p>We also showed a live demo of our Face2Face approach in the Jimmy Kimmel Show. Using a standard webcam, Jimmy Kimmel reenacts a video of Mike Tyson and others.</p>
		<span class="post-date">2016, Apr 28&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://zollhoefer.com/papers/CACM19_F2F/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			
			
		
		
			<span class="post-paper-bibtex"><a href="/posts/face2face_tv/thies2016face.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face2face_gtc/thumb.jpg)" href="/posts/face2face_gtc/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face2face_gtc/">GPU Technology Conference&#58; Interactive Demo of Face2Face</a></h2>


		<!--<p>We present a novel approach for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). The source sequence is also a monocular...</p>-->
		<p>Nvidia invited us to show a demo for our real-time facial reenactment system (Face2Face). Our goal is to animate the facial expressions of a target video by a source actor and re-render the manipulated output video in a photo-realistic fashion.</p>
		<span class="post-date">2016, Apr 07&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://zollhoefer.com/papers/CACM19_F2F/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=Uk0K73eaju8" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/face2face_gtc/thies2016face.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	

  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</div>

  </div>

</body>
</html>
