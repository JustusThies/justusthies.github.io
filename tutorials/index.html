<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<!-- <title>Tutorials & Demos - Justus Thies</title> -->
	<title>Tutorials & Demos</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="Justus Thies" property="og:site_name">
  
    <meta content="Tutorials & Demos" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="Personal Website of Justus Thies covering his publications and teaching courses.
" property="og:description">
  
  
    <meta content="https://justusthies.github.io/tutorials/" property="og:url">
  
  
  
    <meta content="https://justusthies.github.io/assets/img/justus-thies.jpg" property="og:image">
  
  
  

    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@">
    <meta name="twitter:creator" content="@JustusThies">
  
    <meta name="twitter:title" content="Tutorials & Demos">
  
  
    <meta name="twitter:url" content="https://justusthies.github.io/tutorials/">
  
  
    <meta name="twitter:description" content="Personal Website of Justus Thies covering his publications and teaching courses.
">
  
  
    <meta name="twitter:image:src" content="https://justusthies.github.io/assets/img/justus-thies.jpg">
  

	<meta name="description" content="">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicon/apple-touch-icon-144x144.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="/"><img src="/assets/img/justus-thies.jpg" alt="Justus Thies"></a>
      </div>
      <div class="author-name">Justus Thies</div>
	  <div class="author-about">I am a scientific researcher focusing on digital humans, video editing and forgery detection.</div>
    </div>
	

	<section class="subpages">
		<a href="/reconstruction"><div class="subpages-title">Capture & <br> Synthesis</div></a>
		<a href="/forensics"><div class="subpages-title">Multi-media <br> Forensics</div></a>
		<span class="dot"></span>
	</section>
	<section class="subpages">
		<a href="/publications"><div class="subpages-title2">Publications</div></a>
		<a href="/teaching"><div class="subpages-title2">Teaching</div></a>
		<a href="/tutorials"><div class="subpages-title2">Tutorials  & <br> Demos</div></a>
	</section>
	<br><br>
	<section class="subpages">
		<a href="/openings"><div class="subpages-title">Openings</div></a>
	</section>
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
          <li><a href="https://twitter.com/JustusThies" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://youtube.com/channel/UCwmSTvnV-sjtlIlNvWYC6Ow" target="_blank"><i class="fa fa-youtube" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://facebook.com/100012738961011" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
        
        
          <li class="github"><a href="http://github.com/justusthies" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
        
          <li class="email"><a href="mailto:justus.thies@tum.de"><i class="fa fa-envelope-o"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
        <p>2021 &copy; Justus Thies</p>

        <p>Website is based on <a href="https://github.com/artemsheludko/flexible-jekyll" target="_blank">flexible-jekyll</a>.</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->

<div class="content-box clearfix">
  <article class="article-page">
  <div class="page-content"> 
  
	<div class="wrap-content">
		<header class="header-page">
			<h1 class="page-title">Tutorials & Demos</h1>
		</header>
		<div class="page-description">Visual computing is a fast evolving field with a lot of real-world use cases. Especially, the synthesis of photo-realistic content and the modelling of digital humans raised a lot of attention. It is important for us to teach the broad public and to sensitize the people to possible image and video manipulations. We showed demonstrations of our methods at countless exhibitions and conferences, and also in TV reports and shows. Besides the demonstrations, we are also giving tutorials in our research field.
</div>
	</div>


	
	
		<hr>
		<h3 class="post-subtitle">2020</h3>
		<hr>
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/bidt/thumb.jpg)" href="/posts/bidt/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/bidt/">BIDT&#58; Echt oder?</a></h2>


		<!--<p>Was ist ein DeepFake? Die Bezeichnung DeepFake wird umgangssprachlich für jegliche Art der digitalen Bild- und Videomanipulation genutzt. Der Begriff DeepFake wurde vor allem von...</p>-->
		<p>What is the impact of DeepFakes on our society? How does it change our view on digital media? Is the technology a danger or a chance?</p>
		<span class="post-date">2020, Oct 20&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">2 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			
		
			
				
				
			
		
		
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/wipo/thumb.jpg)" href="/posts/wipo/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/wipo/">WIPO&#58; Artifical Intelligence and Intellectual Property</a></h2>


		<!--<p>This virtual exhibition presents current approaches of AI-driven media creation.
It raises interesting questions regarding intellectual property.

Weblink to the official website.

</p>-->
		<p>This virtual exhibition presents current approaches of AI-driven media creation. It raises interesting questions regarding intellectual property.</p>
		<span class="post-date">2020, Sep 18&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			
		
			
				
				
			
		
		
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/neuralrenderingtutorial_cvpr/thumb.jpg)" href="/posts/neuralrenderingtutorial_cvpr/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~atewari/" target="_blank" rel="noopener noreferrer">Ayush Tewari</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.ohadf.com/" target="_blank" rel="noopener noreferrer">Ohad Fried</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://vsitzmann.github.io/" target="_blank" rel="noopener noreferrer">Vincent Sitzmann</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="" target="_blank" rel="noopener noreferrer"></a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://www.kalyans.org/" target="_blank" rel="noopener noreferrer">Kalyan Sunkavalli</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://www.ricardomartinbrualla.com/" target="_blank" rel="noopener noreferrer">Ricardo Martin-Brualla</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://www.cs.cmu.edu/~tsimon/" target="_blank" rel="noopener noreferrer">Tomas Simon</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://jsaragih.org/Home_Page.html" target="_blank" rel="noopener noreferrer">Jason Saragih</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://research.google/people/106687/" target="_blank" rel="noopener noreferrer">Rohit K Pandey</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://www.seanfanello.it/" target="_blank" rel="noopener noreferrer">Sean Fanello</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://stanford.edu/~gordonwz/" target="_blank" rel="noopener noreferrer">Gordon Wetzstein</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.csail.mit.edu/junyanz/" target="_blank" rel="noopener noreferrer">Jun-Yan Zhu</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://graphics.stanford.edu/~maneesh/" target="_blank" rel="noopener noreferrer">Maneesh Agrawala</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://research.adobe.com/person/eli-shechtman/" target="_blank" rel="noopener noreferrer">Eli Shechtman</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://www.danbgoldman.com/" target="_blank" rel="noopener noreferrer">Dan B Goldman</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/neuralrenderingtutorial_cvpr/">CVPR 2020 - Tutorial on Neural Rendering</a></h2>


		<!--<p>Neural rendering is a new class of deep image and video generation approaches that enable explicit or implicit control of scene properties such as illumination,...</p>-->
		<p>Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. This state-of-the-art report summarizes the recent trends and applications of neural rendering.</p>
		<span class="post-date">2020, Apr 08&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://arxiv.org/pdf/2004.03805.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=LCTYRqW-ne8" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/neuralrenderingtutorial_cvpr/tewari2020neuralrendering.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/media_forensics_workshop/thumb.jpg)" href="/posts/media_forensics_workshop/"></a>
	  
	  <div class="post-content">
		
		
						
			<span class="post-author"><a href="https://www.linkedin.com/in/cristiancanton/" target="_blank" rel="noopener noreferrer">Cristian Canton</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.witness.org/portfolio_page/sam-gregory/" target="_blank" rel="noopener noreferrer">Sam Gregory</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://dvl.in.tum.de/team/lealtaixe/" target="_blank" rel="noopener noreferrer">Laura Leal-Taixé</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://chris.bregler.com/" target="_blank" rel="noopener noreferrer">Christoph Bregler</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.ischool.berkeley.edu/people/hany-farid" target="_blank" rel="noopener noreferrer">Hany Farid</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://sergioescalera.com/" target="_blank" rel="noopener noreferrer">Sergio Escalera</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://engineering.purdue.edu/~ace/" target="_blank" rel="noopener noreferrer">Edward Delp</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://www.cim.mcgill.ca/~scott/" target="_blank" rel="noopener noreferrer">Scott McCloskey</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.linkedin.com/in/isabelle-guyon-aa371170/" target="_blank" rel="noopener noreferrer">Isabelle Guyon</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.kitware.com/arslan-basharat/" target="_blank" rel="noopener noreferrer">Arslan Basharat</a>&emsp;</span>
						
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://www.grip.unina.it/people/userprofile/verdoliva.html" target="_blank" rel="noopener noreferrer">Luisa Verdoilva</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://ccc.inaoep.mx/~hugojair/pmwiki/" target="_blank" rel="noopener noreferrer">Hugo Jair Escalante</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.revealnews.org/author/christa-scharfenberg/" target="_blank" rel="noopener noreferrer">Christa Scharfenberg</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://niessnerlab.org/members/andreas_roessler/profile.html" target="_blank" rel="noopener noreferrer">Andreas Rössler</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://www.cbsr.ia.ac.cn/users/jwan/research.html" target="_blank" rel="noopener noreferrer">Jun Wan</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://www.grip.unina.it/people/userprofile/davide_cozzolino.html" target="_blank" rel="noopener noreferrer">Davide Cozzolino</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://research.baidu.com/People/index-view?id=125" target="_blank" rel="noopener noreferrer">Guo Guodong</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/media_forensics_workshop/">CVPR 2020 - Workshop on Media Forensics</a></h2>


		<!--<p>Workshop Website The recent advent of techniques that generate photo-realistic fully synthetic images and videos, and the increasing prevalence of misinformation associated with such fabricated...</p>-->
		<p>This CVPR workshop covers the advances on all fronts of media forensics&#58; from detection of manipulations, biometric implications, misrepresentation/spoofing, etc.</p>
		<span class="post-date">2020, Apr 08&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			
		
			
				
				
			
		
		
			
		</div>
	</article>
	
	
		
			<br>
			<hr>
			<h3 class="post-subtitle">2019</h3>
			<hr>
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face_berlin/thumb.jpg)" href="/posts/face_berlin/"></a>
	  
	  <div class="post-content">
		
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="http://niessnerlab.org/members/andreas_roessler/profile.html" target="_blank" rel="noopener noreferrer">Andreas Rössler</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face_berlin/">Cabinet Meeting&#58; Synthetic Media - Danger or Opportunity?</a></h2>


		<!--<p>In this session we showed several demonstrations of our current projects, to inform the Cabinet of Germany about the risks and the opportunities of synthetic...</p>-->
		<p>In this session we showed several demonstrations of our current projects, to inform the Cabinet of Germany about the risks and the opportunities of synthetic media.</p>
		<span class="post-date">2019, Nov 18&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			
		
			
				
				
			
		
		
			
		</div>
	</article>
	
	
		
			<br>
			<hr>
			<h3 class="post-subtitle">2018</h3>
			<hr>
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face_brussels/thumb.jpg)" href="/posts/face_brussels/"></a>
	  
	  <div class="post-content">
		
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face_brussels/">EU Commission&#58; Information Manipulation</a></h2>


		<!--<p>Invited by the EU Commission, we showed a live demo of Face2Face in Brussles. The topic of the conference was how to protect the election...</p>-->
		<p>Invited by the EU Commission, we showed a demo for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). The topic of the conference was how to protect the election process (EU elections 2019) against interference from outside (cyber crime, fake news).</p>
		<span class="post-date">2018, Oct 02&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://zollhoefer.com/papers/CACM19_F2F/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=eELKSAKBIIM" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/face_brussels/thies2016face.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face_tutorial/thumb.png)" href="/posts/face_tutorial/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face_tutorial/">ECCV 2018&#58; Tutorial on Face Tracking and its Applications</a></h2>


		<!--<p>Course Website The tutorial is about monocular face tracking techniques and also discusses the possible applications. Specifically, the tutorial will cover topics such as: Input...</p>-->
		<p>This invited tutorial is about monocular face tracking techniques and also discusses the possible applications. It is based on our Eurographics state-of-the-art report.</p>
		<span class="post-date">2018, Sep 08&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="http://zollhoefer.com/papers/EG18_FaceSTAR/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			
				
				
			
		
		
			<span class="post-paper-bibtex"><a href="/posts/face_tutorial/zollhoefer2018facestar.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/facestar_eg/teaser.jpg)" href="/posts/facestar_eg/"></a>
	  
	  <div class="post-content">
		
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://la.disneyresearch.com/people/derek-bradley/" target="_blank" rel="noopener noreferrer">Derek Bradley</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~pgarrido/index.html" target="_blank" rel="noopener noreferrer">Pablo Garrido</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://la.disneyresearch.com/people/thabo-beeler/" target="_blank" rel="noopener noreferrer">Thabo Beeler</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://ptrckprz.github.io/" target="_blank" rel="noopener noreferrer">Patrick Perez</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/facestar_eg/">Eurographics 2018&#58; State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications</a></h2>


		<!--<p>The computer graphics and vision communities have dedicated long standing efforts in building computerized tools for reconstructing, tracking, and analyzing human faces based on visual...</p>-->
		<p>This state-of-the-art report session summarizes recent trends in monocular facial performance capture and discusses its applications, which range from performance-based animation to real-time facial reenactment. We focus on methods where the central task is to recover and track a three dimensional model of the human face using optimization-based reconstruction algorithms.</p>
		<span class="post-date">2018, Apr 24&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="http://zollhoefer.com/papers/EG18_FaceSTAR/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			
				
				
			
		
		
			<span class="post-paper-bibtex"><a href="/posts/facestar_eg/zollhoefer2018facestar.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
			<br>
			<hr>
			<h3 class="post-subtitle">2017</h3>
			<hr>
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/facevr_et/thumb.jpg)" href="/posts/facevr_et/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/facevr_et/">SIGGRAPH Emerging Technologies&#58; Demo of FaceVR</a></h2>


		<!--<p>We propose FaceVR, a novel image-based method that enables video teleconferencing in VR based on self-reenactment. State-of-the-art face tracking methods in the VR context are...</p>-->
		<p>We present a novel method for the interactive markerless reconstruction of human heads using a single commodity RGB‐D sensor. Our entire reconstruction pipeline is implemented on the graphics processing unit and allows to obtain high‐quality reconstructions of the human head using an interactive and intuitive reconstruction paradigm.</p>
		<span class="post-date">2017, Aug 03&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://arxiv.org/abs/1610.03151" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=Lg-uGQLNJnQ" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/facevr_et/thies2017facevr_demo.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
			<br>
			<hr>
			<h3 class="post-subtitle">2016</h3>
			<hr>
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/faceincar/teaser.jpg)" href="/posts/faceincar/"></a>
	  
	  <div class="post-content">
		
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/faceincar/">FaceInCar Demo at the National IT Summit 2016</a></h2>


		<!--<p>This exhibit demonstrates the first approach for real-time dense face tracking of a driver based on a monocular video stream. It allows to reconstruct and...</p>-->
		<p>We demonstrate the capabilities of the dense face fitting proposed in Face2Face in the challenging scenario of face tracking in a car including occlusions and strong varying light situations.</p>
		<span class="post-date">2016, Nov 17&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">2 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			
		
			
				
				
			
		
		
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face2face_et/thumb.jpg)" href="/posts/face2face_et/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face2face_et/">SIGGRAPH Emerging Technologies&#58; Real-time Face Capture and Reenactment of RGB Videos</a></h2>


		<!--<p>We present a novel approach for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). The source sequence is also a monocular...</p>-->
		<p>We show a demo for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). Our goal is to animate the facial expressions of a target video by a source actor and re-render the manipulated output video in a photo-realistic fashion.</p>
		<span class="post-date">2016, Jul 28&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://dl.acm.org/citation.cfm?id=2929475" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=lBSFKSpwMQo" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/face2face_et/thies2016face2face_demo.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face2face_tv/thumb.jpg)" href="/posts/face2face_tv/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face2face_tv/">Live-demo of Face2Face in the Jimmy Kimmel Show</a></h2>


		<!--<p>





</p>-->
		<p>We also showed a live demo of our Face2Face approach in the Jimmy Kimmel Show. Using a standard webcam, Jimmy Kimmel reenacts a video of Mike Tyson and others.</p>
		<span class="post-date">2016, Apr 28&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://zollhoefer.com/papers/CACM19_F2F/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			
				
				
			
		
		
			<span class="post-paper-bibtex"><a href="/posts/face2face_tv/thies2016face.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	
	
		
	
	

	<article class="post">
	  
		<a class="post-thumbnail" style="background-image: url(/posts/face2face_gtc/thumb.jpg)" href="/posts/face2face_gtc/"></a>
	  
	  <div class="post-content">
		
		
			
			<span class="post-author-bold"><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/" target="_blank" rel="noopener noreferrer">Marc Stamminger</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span class="post-author"><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
		<h2 class="post-title"><a href="/posts/face2face_gtc/">GPU Technology Conference&#58; Interactive Demo of Face2Face</a></h2>


		<!--<p>We present a novel approach for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). The source sequence is also a monocular...</p>-->
		<p>Nvidia invited us to show a demo for our real-time facial reenactment system (Face2Face). Our goal is to animate the facial expressions of a target video by a source actor and re-render the manipulated output video in a photo-realistic fashion.</p>
		<span class="post-date">2016, Apr 07&nbsp;&nbsp;&nbsp;—&nbsp;</span>
		<span class="post-words">1 minute read&nbsp;&nbsp;&nbsp;&nbsp;</span>

		
			<span class="post-paper-link"><a href="https://zollhoefer.com/papers/CACM19_F2F/paper.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=Uk0K73eaju8" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/face2face_gtc/thies2016face.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
		</div>
	</article>
	

  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</div>

  </div>

</body>
</html>
