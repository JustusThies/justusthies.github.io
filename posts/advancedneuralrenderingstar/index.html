<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<!-- <title>Advances in Neural Rendering - Justus Thies</title> -->
	<title>Advances in Neural Rendering</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="Justus Thies" property="og:site_name">
  
    <meta content="Advances in Neural Rendering" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="This state-of-the-art report on advances in neural rendering focuses on methods that combine classical rendering principles with learned 3D scene representations, often now referred to as neural scene representations. A key advantage of these methods is that they are 3D-consistent by design, enabling applications such as novel viewpoint synthesis of a captured scene." property="og:description">
  
  
    <meta content="https://justusthies.github.io/posts/advancedneuralrenderingstar/" property="og:url">
  
  
    <meta content="2021-11-11T09:00:00+01:00" property="article:published_time">
    <meta content="https://justusthies.github.io/about/" property="article:author">
  
  
    <meta content="https://justusthies.github.io/assets/img/teaser.jpg" property="og:image">
  
  
    
    <meta content="publication" property="article:section">
    
  
  
    
    <meta content="ArXiv" property="article:tag">
    
  

    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@">
    <meta name="twitter:creator" content="@JustusThies">
  
    <meta name="twitter:title" content="Advances in Neural Rendering">
  
  
    <meta name="twitter:url" content="https://justusthies.github.io/posts/advancedneuralrenderingstar/">
  
  
    <meta name="twitter:description" content="This state-of-the-art report on advances in neural rendering focuses on methods that combine classical rendering principles with learned 3D scene representations, often now referred to as neural scene representations. A key advantage of these methods is that they are 3D-consistent by design, enabling applications such as novel viewpoint synthesis of a captured scene.">
  
  
    <meta name="twitter:image:src" content="https://justusthies.github.io/assets/img/teaser.jpg">
  

	<meta name="description" content="This state-of-the-art report on advances in neural rendering focuses on methods that combine classical rendering principles with learned 3D scene representations, often now referred to as neural scene representations. A key advantage of these methods is that they are 3D-consistent by design, enabling applications such as novel viewpoint synthesis of a captured scene.">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicon/apple-touch-icon-144x144.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="/"><img src="/assets/img/justus-thies.jpg" alt="Justus Thies"></a>
      </div>
      <div class="author-name">Justus Thies</div>
	  <div class="author-about">I am a research group leader focusing on digital humans, video editing and forgery detection.</div>
    </div>
	

	<section class="subpages">
		<a href="/reconstruction"><div class="subpages-title">Capture & <br> Synthesis</div></a>
		<a href="/forensics"><div class="subpages-title">Multi-media <br> Forensics</div></a>
		<span class="dot"></span>
	</section>
	<section class="subpages">
		<a href="/publications"><div class="subpages-title2">Publications</div></a>
		<a href="/teaching"><div class="subpages-title2">Teaching</div></a>
		<a href="/tutorials"><div class="subpages-title2">Tutorials  & <br> Demos</div></a>
	</section>
	<br><br>
	<section class="subpages">
		<a href="/openings"><div class="subpages-title">Openings</div></a>
		<a href="https://ncs.is.tuebingen.mpg.de/" target="_blank"><div class="subpages-title">Group Website &#128279;</div></a>
		<a href="/services"><div class="subpages-title">Research Community Services</div></a>
	</section>
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
          <li><a href="https://twitter.com/JustusThies" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://youtube.com/channel/UCwmSTvnV-sjtlIlNvWYC6Ow" target="_blank"><i class="fa fa-youtube" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://facebook.com/100012738961011" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
        
        
          <li class="github"><a href="http://github.com/justusthies" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
        
          <li class="email"><a href="mailto:justus.thies@tuebingen.mpg.de"><i class="fa fa-envelope-o"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
        <p>2021 &copy; Justus Thies</p>

        <p>Website is based on <a href="https://github.com/artemsheludko/flexible-jekyll" target="_blank">flexible-jekyll</a>.</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->

<div class="content-box clearfix">
  <article class="article-page">
		
  <div class="page-content">
    <div class="wrap-content">
      <header class="header-page">
			
			<h1 class="page-title">Advances in Neural Rendering</h1>
			
        <div class="page-date"><span>2021, Nov 11&nbsp;&nbsp;&nbsp;&nbsp;</span></div>
		
			
			<span><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span><a href="https://people.mpi-inf.mpg.de/~atewari/" target="_blank" rel="noopener noreferrer">Ayush Tewari</a>&emsp;</span>
						
		
						
			<span><a href="https://bmild.github.io/" target="_blank" rel="noopener noreferrer">Ben Mildenhall</a>&emsp;</span>
						
		
						
			<span><a href="https://pratulsrinivasan.github.io/" target="_blank" rel="noopener noreferrer">Pratul_Srinivasan</a>&emsp;</span>
						
		
						
			<span><a href="https://people.mpi-inf.mpg.de/~tretschk/" target="_blank" rel="noopener noreferrer">Edgar Tretschk</a>&emsp;</span>
						
		
						
			<span><a href="https://yifita.github.io/" target="_blank" rel="noopener noreferrer">Yifan Wanf</a>&emsp;</span>
						
		
						
			<span><a href="https://christophlassner.de/" target="_blank" rel="noopener noreferrer">Christoph Lassner</a>&emsp;</span>
						
		
						
			<span><a href="https://vsitzmann.github.io/" target="_blank" rel="noopener noreferrer">Vincent Sitzmann</a>&emsp;</span>
						
		
						
			<span><a href="http://www.ricardomartinbrualla.com/" target="_blank" rel="noopener noreferrer">Ricardo Martin-Brualla</a>&emsp;</span>
						
		
						
			<span><a href="" target="_blank" rel="noopener noreferrer"></a>&emsp;</span>
						
		
						
			<span><a href="http://www.cs.cmu.edu/~tsimon/" target="_blank" rel="noopener noreferrer">Tomas Simon</a>&emsp;</span>
						
		
						
			<span><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
						
			<span><a href="https://jonbarron.info/" target="_blank" rel="noopener noreferrer">Jonathan T. Barron</a>&emsp;</span>
						
		
						
			<span><a href="https://stanford.edu/~gordonwz/" target="_blank" rel="noopener noreferrer">Gordon Wetzstein</a>&emsp;</span>
						
		
						
			<span><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
						
			<span><a href="https://people.mpi-inf.mpg.de/~golyanik/" target="_blank" rel="noopener noreferrer">Vladislav Golyanik</a>&emsp;</span>
						
		
      </header>
	  
	  
	    <div class="page-cover-image">
		  <figure>
			<!--<img class="page-image" src=/assets/img/teaser.jpg alt="Advances in Neural Rendering">-->
			<img class="page-image" src=teaser.jpg alt="Advances in Neural Rendering">
			
		  </figure>
		</div> <!-- End Page Cover Image -->
	  
	  
      <p>Synthesizing photo-realistic images and videos is at the heart of computer graphics and has been the focus of decades of research. Traditionally, synthetic images of a scene are generated using rendering algorithms such as rasterization or ray tracing, which take specifically defined representations of geometry and material properties as input. Collectively, these inputs define the actual scene and what is rendered, and are referred to as the scene representation (where a scene consists of one or more objects). Example scene representations are triangle meshes with accompanied textures (e.g., created by an artist), point clouds (e.g., from a depth sensor), volumetric grids (e.g., from a CT scan), or implicit surface functions (e.g., truncated signed distance fields). The reconstruction of such a scene representation from observations using  differentiable rendering losses is known as inverse graphics or inverse rendering. Neural rendering is closely related, and combines ideas from  classical computer graphics and machine learning to create algorithms for synthesizing images from real-world observations. Neural rendering is a leap forward towards the goal of synthesizing photo-realistic image and video content. In recent years, we have seen immense progress in this field through hundreds of publications that show different ways to inject learnable components into the rendering pipeline.</p>

<p>This state-of-the-art report on advances in neural rendering  focuses on methods that combine classical rendering principles with learned 3D scene representations, often now referred to as neural scene representations. A key advantage of these methods is that they are 3D-consistent by design, enabling applications such as novel viewpoint synthesis of a captured scene. In addition to methods that handle static scenes, we cover neural scene representations for modeling non-rigidly deforming objects and scene editing and composition. While most of these approaches are scene-specific, we also discuss techniques that generalize across object classes and can be used for generative tasks. In addition to reviewing these state-of-the-art methods, we provide an overview of fundamental concepts and definitions used in the current literature. We conclude with a discussion on open challenges and social implications.</p>

	  
	  
		
			<span class="post-paper-link"><a href="https://arxiv.org/pdf/2111.05849.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			
					
			
		
		
			<span class="post-paper-bibtex"><a href="/posts/advancedneuralrenderingstar/tewari2021advances.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
	  

		
			
		
	  
      <div class="page-footer">
        <!-- <div class="page-share"> -->
          <!-- <a href="https://twitter.com/intent/tweet?text=Advances in Neural Rendering&url=https://justusthies.github.io/posts/advancedneuralrenderingstar/" title="Share on Twitter" rel="nofollow" target="_blank">Twitter</a> -->
          <!-- <a href="https://facebook.com/sharer.php?u=https://justusthies.github.io/posts/advancedneuralrenderingstar/" title="Share on Facebook" rel="nofollow" target="_blank">Facebook</a> -->
          <!-- <a href="https://plus.google.com/share?url=https://justusthies.github.io/posts/advancedneuralrenderingstar/" title="Share on Google+" rel="nofollow" target="_blank">Google+</a> -->
        <!-- </div> -->
        <div class="page-tag">
          
            <a href="/tags#ArXiv" class="tag">&#35; ArXiv</a>
          
        </div>
      </div>
    </div> <!-- End Wrap Content -->
  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</div>

  </div>

</body>
</html>
