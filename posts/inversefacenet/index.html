<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<!-- <title>InverseFaceNet&#58; Deep Monocular Inverse Face Rendering - Justus Thies</title> -->
	<title>InverseFaceNet&#58; Deep Monocular Inverse Face Rendering</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="Justus Thies" property="og:site_name">
  
    <meta content="InverseFaceNet&#58; Deep Monocular Inverse Face Rendering" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="We introduce InverseFaceNet, a deep convolutional inverse rendering framework for faces that jointly estimates facial pose, shape, expression, reflectance and illumination from a single input image. This enables advanced real-time editing of facial imagery, such as appearance editing and relighting." property="og:description">
  
  
    <meta content="https://justusthies.github.io/posts/inversefacenet/" property="og:url">
  
  
    <meta content="2018-05-16T11:00:00+02:00" property="article:published_time">
    <meta content="https://justusthies.github.io/about/" property="article:author">
  
  
    <meta content="https://justusthies.github.io/assets/img/teaser.jpg" property="og:image">
  
  
    
    <meta content="publication" property="article:section">
    
  
  
    
    <meta content="CVPR" property="article:tag">
    
  

    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@">
    <meta name="twitter:creator" content="@JustusThies">
  
    <meta name="twitter:title" content="InverseFaceNet&#58; Deep Monocular Inverse Face Rendering">
  
  
    <meta name="twitter:url" content="https://justusthies.github.io/posts/inversefacenet/">
  
  
    <meta name="twitter:description" content="We introduce InverseFaceNet, a deep convolutional inverse rendering framework for faces that jointly estimates facial pose, shape, expression, reflectance and illumination from a single input image. This enables advanced real-time editing of facial imagery, such as appearance editing and relighting.">
  
  
    <meta name="twitter:image:src" content="https://justusthies.github.io/assets/img/teaser.jpg">
  

	<meta name="description" content="We introduce InverseFaceNet, a deep convolutional inverse rendering framework for faces that jointly estimates facial pose, shape, expression, reflectance and illumination from a single input image. This enables advanced real-time editing of facial imagery, such as appearance editing and relighting.">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicon/apple-touch-icon-144x144.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="/"><img src="/assets/img/justus-thies.jpg" alt="Justus Thies"></a>
      </div>
      <div class="author-name">Justus Thies</div>
	  <div class="author-about">I am a research group leader focusing on digital humans, video editing and forgery detection.</div>
    </div>
	

	<section class="subpages">
		<a href="/reconstruction"><div class="subpages-title">Capture & <br> Synthesis</div></a>
		<a href="/forensics"><div class="subpages-title">Multi-media <br> Forensics</div></a>
		<span class="dot"></span>
	</section>
	<section class="subpages">
		<a href="/publications"><div class="subpages-title2">Publications</div></a>
		<a href="/teaching"><div class="subpages-title2">Teaching</div></a>
		<a href="/tutorials"><div class="subpages-title2">Tutorials  & <br> Demos</div></a>
	</section>
	<br><br>
	<section class="subpages">
		<a href="/openings"><div class="subpages-title">Openings</div></a>
		<a href="https://ncs.is.tuebingen.mpg.de/" target="_blank"><div class="subpages-title">Group Website &#128279;</div></a>
		<a href="/services"><div class="subpages-title">Research Community Services</div></a>
	</section>
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
          <li><a href="https://twitter.com/JustusThies" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://youtube.com/channel/UCwmSTvnV-sjtlIlNvWYC6Ow" target="_blank"><i class="fa fa-youtube" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://facebook.com/100012738961011" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
        
        
          <li class="github"><a href="http://github.com/justusthies" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
        
          <li class="email"><a href="mailto:justus.thies@tuebingen.mpg.de"><i class="fa fa-envelope-o"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
        <p>2022 &copy; Justus Thies</p>

        <p>Website is based on <a href="https://github.com/artemsheludko/flexible-jekyll" target="_blank">flexible-jekyll</a>.</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->

<div class="content-box clearfix">
  <article class="article-page">
		
  <div class="page-content">
    <div class="wrap-content">
      <header class="header-page">
			
			<h1 class="page-title">InverseFaceNet&#58; Deep Monocular Inverse Face Rendering</h1>
			
        <div class="page-date"><span>2018, May 16&nbsp;&nbsp;&nbsp;&nbsp;</span></div>
		
						
			<span><a href="https://people.mpi-inf.mpg.de/~hyeongwoo/" target="_blank" rel="noopener noreferrer">Hyeongwoo Kim</a>&emsp;</span>
						
		
						
			<span><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollh√∂fer</a>&emsp;</span>
						
		
						
			<span><a href="https://people.mpi-inf.mpg.de/~atewari/" target="_blank" rel="noopener noreferrer">Ayush Tewari</a>&emsp;</span>
						
		
			
			<span><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span><a href="https://richardt.name/" target="_blank" rel="noopener noreferrer">Christian Richardt</a>&emsp;</span>
						
		
						
			<span><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
      </header>
	  
	  
	    <div class="page-cover-image">
		  <figure>
			<!--<img class="page-image" src=/assets/img/teaser.jpg alt="InverseFaceNet&#58; Deep Monocular Inverse Face Rendering">-->
			<img class="page-image" src=teaser.jpg alt="InverseFaceNet&#58; Deep Monocular Inverse Face Rendering">
			
		  </figure>
		</div> <!-- End Page Cover Image -->
	  
	  
      <p>We introduce InverseFaceNet, a deep convolutional inverse rendering framework for faces that jointly estimates facial pose, shape, expression, reflectance and illumination from a single input image.
By estimating all parameters from just a single image, advanced editing possibilities on a single face image, such as appearance editing and relighting, become feasible in real time.
Most previous learning-based face reconstruction approaches do not jointly recover all dimensions, or are severely limited in terms of visual quality.
In contrast, we propose to recover high-quality facial pose, shape, expression, reflectance and illumination using a deep neural network that is trained using a large, synthetically created training corpus.
Our approach builds on a novel loss function that measures model-space similarity directly in parameter space and significantly improves reconstruction accuracy.
We further propose a self-supervised bootstrapping process in the network training loop, which iteratively updates the synthetic training corpus to better reflect the distribution of real-world imagery.
We demonstrate that this strategy outperforms completely synthetically trained networks.
Finally, we show high-quality reconstructions and compare our approach to several state-of-the-art approaches.</p>

	  
	  
		
			<span class="post-paper-link"><a href="https://arxiv.org/abs/1703.10956" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			
				<span class="post-video-link"><a href="http://vimeo.com/262874743?dnt=1" target="_blank">[Video]</a>&nbsp;</span>
			
		
		
			<span class="post-paper-bibtex"><a href="/posts/inversefacenet/kim2018inversefacenet.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
	  

		
			
			<iframe  width="898" height="505" src=https://player.vimeo.com/video/262874743?dnt=1 frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>
			
		
	  
      <div class="page-footer">
        <!-- <div class="page-share"> -->
          <!-- <a href="https://twitter.com/intent/tweet?text=InverseFaceNet&#58; Deep Monocular Inverse Face Rendering&url=https://justusthies.github.io/posts/inversefacenet/" title="Share on Twitter" rel="nofollow" target="_blank">Twitter</a> -->
          <!-- <a href="https://facebook.com/sharer.php?u=https://justusthies.github.io/posts/inversefacenet/" title="Share on Facebook" rel="nofollow" target="_blank">Facebook</a> -->
          <!-- <a href="https://plus.google.com/share?url=https://justusthies.github.io/posts/inversefacenet/" title="Share on Google+" rel="nofollow" target="_blank">Google+</a> -->
        <!-- </div> -->
        <div class="page-tag">
          
            <a href="/tags#CVPR" class="tag">&#35; CVPR</a>
          
        </div>
      </div>
    </div> <!-- End Wrap Content -->
  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</div>

  </div>

</body>
</html>
