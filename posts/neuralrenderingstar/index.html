<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<!-- <title>State of the Art on Neural Rendering - Justus Thies</title> -->
	<title>State of the Art on Neural Rendering</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="Justus Thies" property="og:site_name">
  
    <meta content="State of the Art on Neural Rendering" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. This state-of-the-art report summarizes the recent trends and applications of neural rendering." property="og:description">
  
  
    <meta content="https://justusthies.github.io/posts/neuralrenderingstar/" property="og:url">
  
  
    <meta content="2020-04-08T10:00:00+02:00" property="article:published_time">
    <meta content="https://justusthies.github.io/about/" property="article:author">
  
  
    <meta content="https://justusthies.github.io/assets/img/teaser.jpg" property="og:image">
  
  
    
    <meta content="publication" property="article:section">
    
  
  
    
    <meta content="EG" property="article:tag">
    
  

    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@">
    <meta name="twitter:creator" content="@JustusThies">
  
    <meta name="twitter:title" content="State of the Art on Neural Rendering">
  
  
    <meta name="twitter:url" content="https://justusthies.github.io/posts/neuralrenderingstar/">
  
  
    <meta name="twitter:description" content="Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. This state-of-the-art report summarizes the recent trends and applications of neural rendering.">
  
  
    <meta name="twitter:image:src" content="https://justusthies.github.io/assets/img/teaser.jpg">
  

	<meta name="description" content="Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. This state-of-the-art report summarizes the recent trends and applications of neural rendering.">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicon/apple-touch-icon-144x144.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="/"><img src="/assets/img/justus-thies.jpg" alt="Justus Thies"></a>
      </div>
      <div class="author-name">Justus Thies</div>
	  <div class="author-about">I am a postdoctoral researcher focusing on digital humans, video editing and forgery detection.</div>
    </div>
	

	<section class="subpages">	
		<a href="/publications"><div class="subpages-title">Publications</div></a>
    <a href="/teaching"><div class="subpages-title">Teaching</div></a>
    <a href="/tutorials"><div class="subpages-title">Tutorials  & Demos</div></a>
	</section>
	
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
          <li><a href="https://twitter.com/JustusThies" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://facebook.com/100012738961011" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
        
        
          <li class="github"><a href="http://github.com/justusthies" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
        
          <li class="email"><a href="mailto:justus.thies@tum.de"><i class="fa fa-envelope-o"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
        <p>2020 &copy; Justus Thies</p>

        <p>Website is based on <a href="https://github.com/artemsheludko/flexible-jekyll" target="_blank">flexible-jekyll</a>.</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->

<div class="content-box clearfix">
  <article class="article-page">
		
  <div class="page-content">
    <div class="wrap-content">
      <header class="header-page">
			
			<h1 class="page-title">State of the Art on Neural Rendering</h1>
			
        <div class="page-date"><span>2020, Apr 08&nbsp;&nbsp;&nbsp;&nbsp;</span></div>
		
			
			<span><a href="/">Justus Thies</a>&emsp;</span>
						
		
						
			<span><a href="https://people.mpi-inf.mpg.de/~atewari/" target="_blank" rel="noopener noreferrer">Ayush Tewari</a>&emsp;</span>
						
		
						
			<span><a href="https://www.ohadf.com/" target="_blank" rel="noopener noreferrer">Ohad Fried</a>&emsp;</span>
						
		
						
			<span><a href="https://vsitzmann.github.io/" target="_blank" rel="noopener noreferrer">Vincent Sitzmann</a>&emsp;</span>
						
		
						
			<span><a href="" target="_blank" rel="noopener noreferrer"></a>&emsp;</span>
						
		
						
			<span><a href="http://www.kalyans.org/" target="_blank" rel="noopener noreferrer">Kalyan Sunkavalli</a>&emsp;</span>
						
		
						
			<span><a href="http://www.ricardomartinbrualla.com/" target="_blank" rel="noopener noreferrer">Ricardo Martin-Brualla</a>&emsp;</span>
						
		
						
			<span><a href="http://www.cs.cmu.edu/~tsimon/" target="_blank" rel="noopener noreferrer">Tomas Simon</a>&emsp;</span>
						
		
						
			<span><a href="http://jsaragih.org/Home_Page.html" target="_blank" rel="noopener noreferrer">Jason Saragih</a>&emsp;</span>
						
		
						
			<span><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nießner</a>&emsp;</span>
						
		
						
			<span><a href="https://research.google/people/106687/" target="_blank" rel="noopener noreferrer">Rohit K Pandey</a>&emsp;</span>
						
		
						
			<span><a href="http://www.seanfanello.it/" target="_blank" rel="noopener noreferrer">Sean Fanello</a>&emsp;</span>
						
		
						
			<span><a href="https://stanford.edu/~gordonwz/" target="_blank" rel="noopener noreferrer">Gordon Wetzstein</a>&emsp;</span>
						
		
						
			<span><a href="https://people.csail.mit.edu/junyanz/" target="_blank" rel="noopener noreferrer">Jun-Yan Zhu</a>&emsp;</span>
						
		
						
			<span><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank" rel="noopener noreferrer">Christian Theobalt</a>&emsp;</span>
						
		
						
			<span><a href="http://graphics.stanford.edu/~maneesh/" target="_blank" rel="noopener noreferrer">Maneesh Agrawala</a>&emsp;</span>
						
		
						
			<span><a href="https://research.adobe.com/person/eli-shechtman/" target="_blank" rel="noopener noreferrer">Eli Shechtman</a>&emsp;</span>
						
		
						
			<span><a href="http://www.danbgoldman.com/" target="_blank" rel="noopener noreferrer">Dan B Goldman</a>&emsp;</span>
						
		
						
			<span><a href="https://zollhoefer.com" target="_blank" rel="noopener noreferrer">Michael Zollhöfer</a>&emsp;</span>
						
		
      </header>
	  
	  
	    <div class="page-cover-image">
		  <figure>
			<!--<img class="page-image" src=/assets/img/teaser.jpg alt="State of the Art on Neural Rendering">-->
			<img class="page-image" src=teaser.jpg alt="State of the Art on Neural Rendering">
			
		  </figure>
		</div> <!-- End Page Cover Image -->
	  
	  
      <p>Efficient rendering of photo-realistic virtual worlds is a long standing effort of computer graphics. Modern graphics techniques have succeeded in synthesizing photo-realistic images from hand-crafted scene representations.
However, the automatic generation of shape, materials, lighting, and other aspects of scenes  remains a challenging problem that, if solved, would make photo-realistic computer graphics more widely accessible.
Concurrently, progress in computer vision and machine learning have given rise to a new approach to image synthesis and editing, namely deep generative models.
Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training.
With a plethora of applications in computer graphics and vision, neural rendering is poised to become a new area in the graphics community, yet no survey of this emerging field exists.
This state-of-the-art report summarizes the recent trends and applications of neural rendering.
We focus on approaches that combine classic computer graphics techniques with deep generative models to obtain controllable and photo-realistic outputs.
Starting with an overview of the underlying computer graphics and machine learning concepts, we discuss critical aspects of neural rendering approaches.
Specifically, our emphasis is on the type of control, i.e., how the control is provided, which parts of the pipeline are learned, explicit vs.~implicit control, generalization, and stochastic vs.~deterministic synthesis.
The second half of this state-of-the-art report is focused on the many important use cases for the described algorithms such as novel view synthesis, semantic photo manipulation, facial and body reenactment, relighting, free-viewpoint video, and the creation of photo-realistic avatars for virtual and augmented reality telepresence.
Finally, we conclude with a discussion of the social implications of such technology and investigate open research problems.</p>

	  
	  
		
			<span class="post-paper-link"><a href="https://arxiv.org/pdf/2004.03805.pdf" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			
					
			
		
		
			<span class="post-paper-bibtex"><a href="/posts/neuralrenderingstar/tewari2020neuralrendering.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
	  

		
			
		
	  
      <div class="page-footer">
        <!-- <div class="page-share"> -->
          <!-- <a href="https://twitter.com/intent/tweet?text=State of the Art on Neural Rendering&url=https://justusthies.github.io/posts/neuralrenderingstar/" title="Share on Twitter" rel="nofollow" target="_blank">Twitter</a> -->
          <!-- <a href="https://facebook.com/sharer.php?u=https://justusthies.github.io/posts/neuralrenderingstar/" title="Share on Facebook" rel="nofollow" target="_blank">Facebook</a> -->
          <!-- <a href="https://plus.google.com/share?url=https://justusthies.github.io/posts/neuralrenderingstar/" title="Share on Google+" rel="nofollow" target="_blank">Google+</a> -->
        <!-- </div> -->
        <div class="page-tag">
          
            <a href="/tags#EG" class="tag">&#35; EG</a>
          
        </div>
      </div>
    </div> <!-- End Wrap Content -->
  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</div>

  </div>

</body>
</html>
