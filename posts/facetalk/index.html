<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<!-- <title>FaceTalk - Audio-Driven Motion Diffusion for Neural Parametric Head Models - Graphics & Vision</title> -->
	<title>FaceTalk - Audio-Driven Motion Diffusion for Neural Parametric Head Models</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="Graphics & Vision" property="og:site_name">
  
    <meta content="FaceTalk - Audio-Driven Motion Diffusion for Neural Parametric Head Models" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="We introduce FaceTalk, a novel generative approach designed for synthesizing high-fidelity 3D motion sequences of talking human heads from input audio signal. To capture the expressive, detailed nature of human heads, including hair, ears, and finer-scale eye movements, we propose to couple speech signal with the latent space of neural parametric head models to create high-fidelity, temporally coherent motion sequences" property="og:description">
  
  
    <meta content="https://justusthies.github.io/posts/facetalk/" property="og:url">
  
  
    <meta content="2024-01-01T10:00:00+01:00" property="article:published_time">
    <meta content="https://justusthies.github.io/about/" property="article:author">
  
  
    <meta content="https://justusthies.github.io/assets/img/teaser.jpg" property="og:image">
  
  
    
    <meta content="publication" property="article:section">
    
  
  
    
    <meta content="CVPR" property="article:tag">
    
  

    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@">
    <meta name="twitter:creator" content="@JustusThies">
  
    <meta name="twitter:title" content="FaceTalk - Audio-Driven Motion Diffusion for Neural Parametric Head Models">
  
  
    <meta name="twitter:url" content="https://justusthies.github.io/posts/facetalk/">
  
  
    <meta name="twitter:description" content="We introduce FaceTalk, a novel generative approach designed for synthesizing high-fidelity 3D motion sequences of talking human heads from input audio signal. To capture the expressive, detailed nature of human heads, including hair, ears, and finer-scale eye movements, we propose to couple speech signal with the latent space of neural parametric head models to create high-fidelity, temporally coherent motion sequences">
  
  
    <meta name="twitter:image:src" content="https://justusthies.github.io/assets/img/teaser.jpg">
  

	<meta name="description" content="We introduce FaceTalk, a novel generative approach designed for synthesizing high-fidelity 3D motion sequences of talking human heads from input audio signal. To capture the expressive, detailed nature of human heads, including hair, ears, and finer-scale eye movements, we propose to couple speech signal with the latent space of neural parametric head models to create high-fidelity, temporally coherent motion sequences">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicon/apple-touch-icon-144x144.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="/"><img src="/assets/img/gv_crop.jpg" alt="Graphics & Vision"></a>
      </div>
      <div class="author-name">Graphics & Vision</div>
	  <div class="author-about">Prof. Justus Thies, TU Darmstadt</div>
    </div>
	

	<section class="subpages">
		<a href="/reconstruction"><div class="subpages-title">Capture & <br> Synthesis</div></a>
		<a href="/forensics"><div class="subpages-title">Multi-media <br> Forensics</div></a>
		<span class="dot"></span>
	</section>
	<section class="subpages">
		<a href="/publications"><div class="subpages-title2">Publications</div></a>
		<a href="/teaching"><div class="subpages-title2">Teaching</div></a>
		<a href="/tutorials"><div class="subpages-title2">Tutorials  & <br> Demos</div></a>
	</section>
	<br><br>
	<section class="subpages">
		<a href="/openings"><div class="subpages-title">Openings</div></a>
		<a href="https://ncs.is.tuebingen.mpg.de/" target="_blank"><div class="subpages-title">Group Website &#128279;</div></a>
		<a href="/services"><div class="subpages-title">Research Community Services</div></a>
	</section>
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
          <li><a href="https://twitter.com/JustusThies" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://youtube.com/channel/UCwmSTvnV-sjtlIlNvWYC6Ow" target="_blank"><i class="fa fa-youtube" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://facebook.com/100012738961011" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
        
        
          <li class="github"><a href="http://github.com/justusthies" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
          <li class="linkedin"><a href="https://in.linkedin.com/in/justus-thies-b46141257" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        
        
          <li class="email"><a href="mailto:justus.thies@tu-darmstadt.de"><i class="fa fa-envelope-o"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
        <p>2025 &copy; Graphics & Vision</p>

        <p>Website is based on <a href="https://github.com/artemsheludko/flexible-jekyll" target="_blank">flexible-jekyll</a>.</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->

<div class="content-box clearfix">
  <article class="article-page">
		
  <div class="page-content">
    <div class="wrap-content">
      <header class="header-page">
		
			<h1 class="page-title">FaceTalk&#58; Audio-Driven Motion Diffusion for Neural Parametric Head Models</h1>
			
        <div class="page-date"><span>2024, Jan 01&nbsp;&nbsp;&nbsp;&nbsp;</span></div>
		
						
			<span><a href="https://niessnerlab.org/members/shivangi_aneja/profile.html" target="_blank" rel="noopener noreferrer">Shivangi Aneja</a>&emsp;</span>
						
		
						
			<span><a href="/" target="_blank" rel="noopener noreferrer">Justus Thies</a>&emsp;</span>
						
		
						
			<span><a href="https://angeladai.github.io" target="_blank" rel="noopener noreferrer">Angela Dai</a>&emsp;</span>
						
		
						
			<span><a href="https://niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nie√üner</a>&emsp;</span>
						
		

		<div class="page-tag">
          
            <a href="/tags#CVPR" class="tag">CVPR</a>
          
        </div>
      </header>
	  
	  
	    <div class="page-cover-image">
		  <figure>
			<!--<img class="page-image" src=/assets/img/teaser.jpg alt="FaceTalk - Audio-Driven Motion Diffusion for Neural Parametric Head Models">-->
			<img class="page-image" src=teaser.jpg alt="FaceTalk - Audio-Driven Motion Diffusion for Neural Parametric Head Models">
			
		  </figure>
		</div> <!-- End Page Cover Image -->
	  
	  
      <p>We introduce FaceTalk, a novel generative approach designed for synthesizing high-fidelity 3D motion sequences of talking human heads from input audio signal. To capture the expressive, detailed nature of human heads, including hair, ears, and finer-scale eye movements, we propose to couple speech signal with the latent space of neural parametric head models to create high-fidelity, temporally coherent motion sequences. We propose a new latent diffusion model for this task, operating in the expression space of neural parametric head models, to synthesize audio-driven realistic head sequences. In the absence of a dataset with corresponding NPHM expressions to audio, we optimize for these correspondences to produce a dataset of temporally-optimized NPHM expressions fit to audio-video recordings of people talking. To the best of our knowledge, this is the first work to propose a generative approach for realistic and high-quality motion synthesis of volumetric human heads, representing a significant advancement in the field of audio-driven 3D animation. Notably, our approach stands out in its ability to generate plausible motion sequences that can produce high-fidelity head animation coupled with the NPHM shape space. Our experimental results substantiate the effectiveness of FaceTalk, consistently achieving superior and visually natural motion, encompassing diverse facial expressions and styles, outperforming existing methods by 75% in perceptual user study evaluation.</p>

	  
	  
		
			<span class="post-paper-link"><a href="https://arxiv.org/pdf/2312.08459" target="_blank">[Paper]</a>&nbsp;</span>
			
		
			<span class="post-video-link"><a href="https://www.youtube.com/watch?v=7Jf0kawrA3Q" target="_blank">[Video]</a>&nbsp;</span>
		
		
			<span class="post-paper-bibtex"><a href="/posts/facetalk/aneja2024facetalk.bib" target="_blank">[Bibtex]</a>&nbsp;</span>
			
	  

		
		<iframe width="898" height="505" src=https://www.youtube-nocookie.com/embed/7Jf0kawrA3Q frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
		<div class="page-cover-image">
		</div> <!-- End Page Cover Image -->
		
	  
      <div class="page-footer">
        <!-- <div class="page-share"> -->
          <!-- <a href="https://twitter.com/intent/tweet?text=FaceTalk - Audio-Driven Motion Diffusion for Neural Parametric Head Models&url=https://justusthies.github.io/posts/facetalk/" title="Share on Twitter" rel="nofollow" target="_blank">Twitter</a> -->
          <!-- <a href="https://facebook.com/sharer.php?u=https://justusthies.github.io/posts/facetalk/" title="Share on Facebook" rel="nofollow" target="_blank">Facebook</a> -->
          <!-- <a href="https://plus.google.com/share?url=https://justusthies.github.io/posts/facetalk/" title="Share on Google+" rel="nofollow" target="_blank">Google+</a> -->
        <!-- </div> -->
        <!--<div class="page-tag">
          
            <a href="/tags#CVPR" class="tag">&#35; CVPR</a>
          
        </div>-->
      </div>
    </div> <!-- End Wrap Content -->
  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</div>

  </div>

</body>
</html>
